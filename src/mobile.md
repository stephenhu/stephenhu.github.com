a lot of people in the high-tech industry have been talking about mobile
first for a long time, the meaning behind this is quite literally to create mobile
apps before you go with anything else, just think what the world would be like if
uber (taxi mobile app) created a web app before even starting to create its mobile
application, no gps functionality to tell drivers where you are, and you'd have to
have a computer or mobile browser to summon a taxi.  i think the biggest reason for
going mobile first is because of the much more refined user experience on smartphones,
you have the ability to leverage 3 of the 5 senses (visible, audible, and touchable),
the screens are much smaller than computer monitors so designers are forced to use
simpler layouts, and end users have more freedom with smartphones, compute anywhere.  web sites
in general were built before the days of touch screen interfaces and at most leverage
2 of the 5 senses (visual, auditory), they were built for computers with a clunky
monitor, mouse, and keyboard, or a clunky laptop that will never be as easy to carry
around as your smartphone.

a counter argument would be that the number of users with smartphones is much less
than the number of users with computers, but think of the target smartphone user,
this is a user with some sophistication, potentially some spending power, with
the need to leverage data services and applications everywhere, this is a very
exciting user base!  gps and phone services also give applications more functionality
over a personal computer.

i long to see the days where all 5 senses can be leveraged by smartphones, the last
two being smellable and tastable, we're already seeing some inroads being made with
devices that help measure alcoholic intake and imagine some of the sensors from the
public bathroom air freshner could be leveraged.  and i think the current 3 senses
each have dimensions where innovation can take place, like for example audible senses,
mostly this is input, we listen to music on our phones, we set alarms each day, and
we can hear the feedback from pressing on buttons for applications, but things like
speech recognition are still pretty weak for smartphones, sure there's siri and android
provides lots of functionality, but just ask yourself how much your time is spent
tapping on smartphone applications as opposed to speaking (what's up not counted).

